{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd \n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_main= df[['Summary', 'Text']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["###########        skip ############\n","import re\n","import unicodedata\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","nltk.download('wordnet')\n","\n","# Function to remove HTML tags\n","def remove_html_tags(text):\n","    clean_text = re.sub(r'<.*?>', '', text)\n","    return clean_text\n","\n","# Function to remove accented characters\n","def remove_accented_chars(text):\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","    return text\n","\n","# Function to remove special characters\n","def remove_special_characters(text):\n","    clean_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    return clean_text\n","\n","# Function for lemmatize \n","lemmatizer = WordNetLemmatizer()\n","def lemmatize_text(text):\n","    tokens = text.split()\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","    return ' '.join(lemmatized_tokens)\n","\n","# Function to lowerCase \n","def normalize_text(text):\n","    return text.lower()\n","\n","# Fill missing values with an empty string\n","join_df['reviewText'] = join_df['reviewText'].fillna('')\n","\n","# Apply all preprocessing steps to the 'reviewText' column\n","join_df['reviewText'] = (join_df['reviewText']\n","                         .apply(remove_html_tags)\n","                         .apply(remove_accented_chars)\n","                         .apply(remove_special_characters)\n","                         .apply(lemmatize_text)\n","                         .apply(normalize_text))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re\n","from bs4 import BeautifulSoup\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","\n","\n","def preprocess(text):\n","    if isinstance(text,str):\n","        text = BeautifulSoup(text, 'html.parser').get_text()\n","        tokens = word_tokenize(text)\n","        tokens = [token.lower() for token in tokens]\n","        stop_words = set(stopwords.words('english'))\n","        tokens = [token for token in tokens if token not in stop_words]\n","        lemmatizer = WordNetLemmatizer()\n","        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","        tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens if token.strip() != '']\n","        processed_text = ' '.join(tokens)\n","        return processed_text\n","    else:\n","        return \"\"\n","df_main.loc[:,['Text', 'Summary']] = df_main[['Text', 'Summary']].applymap(preprocess)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_main = df_main.dropna().reset_index(drop=True)\n","# df_main = df_main.drop_duplicates().reset_index(drop=True)\n","# df_main = df_main[df_main['Summary']!='']\n","# df_main = df_main[df_main['Text']!='']\n","# df_main.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_main = df_main[['Summary', 'Text']].astype(str)\n","# df_main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:27.337178Z","iopub.status.busy":"2024-04-22T21:58:27.336808Z","iopub.status.idle":"2024-04-22T21:58:29.156621Z","shell.execute_reply":"2024-04-22T21:58:29.155468Z","shell.execute_reply.started":"2024-04-22T21:58:27.337149Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>good quality dog food</td>\n","      <td>i have bought several of the vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>not as advertised</td>\n","      <td>product arrived labeled as jumbo salted peanut...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>delight says it all</td>\n","      <td>this is a confection that has been around a fe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cough medicine</td>\n","      <td>if you are looking for the secret ingredient i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great taffy</td>\n","      <td>great taffy at a great price there was a wide ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>394463</th>\n","      <td>will not do without</td>\n","      <td>great for sesame chickenthis is a good if not ...</td>\n","    </tr>\n","    <tr>\n","      <th>394464</th>\n","      <td>disappointed</td>\n","      <td>im disappointed with the flavor the chocolate ...</td>\n","    </tr>\n","    <tr>\n","      <th>394465</th>\n","      <td>perfect for our maltipoo</td>\n","      <td>these stars are small so you can give 1015 of ...</td>\n","    </tr>\n","    <tr>\n","      <th>394466</th>\n","      <td>favorite training and reward treat</td>\n","      <td>these are the best treats for training and rew...</td>\n","    </tr>\n","    <tr>\n","      <th>394467</th>\n","      <td>great honey</td>\n","      <td>i am very satisfied product is as advertised i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>394468 rows × 2 columns</p>\n","</div>"],"text/plain":["                                   Summary  \\\n","0                    good quality dog food   \n","1                        not as advertised   \n","2                      delight says it all   \n","3                           cough medicine   \n","4                              great taffy   \n","...                                    ...   \n","394463                 will not do without   \n","394464                        disappointed   \n","394465            perfect for our maltipoo   \n","394466  favorite training and reward treat   \n","394467                         great honey   \n","\n","                                                     Text  \n","0       i have bought several of the vitality canned d...  \n","1       product arrived labeled as jumbo salted peanut...  \n","2       this is a confection that has been around a fe...  \n","3       if you are looking for the secret ingredient i...  \n","4       great taffy at a great price there was a wide ...  \n","...                                                   ...  \n","394463  great for sesame chickenthis is a good if not ...  \n","394464  im disappointed with the flavor the chocolate ...  \n","394465  these stars are small so you can give 1015 of ...  \n","394466  these are the best treats for training and rew...  \n","394467  i am very satisfied product is as advertised i...  \n","\n","[394468 rows x 2 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import pickle\n","\n","# reading pickel file \n","with open('/kaggle/input/summary1/df_main.pkl', 'rb') as f:\n","    # Load the data from the file\n","    df_main = pickle.load(f)\n","\n","df_main"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:31.194849Z","iopub.status.busy":"2024-04-22T21:58:31.194214Z","iopub.status.idle":"2024-04-22T21:58:31.201141Z","shell.execute_reply":"2024-04-22T21:58:31.200121Z","shell.execute_reply.started":"2024-04-22T21:58:31.194806Z"},"trusted":true},"outputs":[],"source":["df_subset = df_main[:1000]\n","data = df_subset.reset_index(drop=True)\n","data"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:32.365182Z","iopub.status.busy":"2024-04-22T21:58:32.364832Z","iopub.status.idle":"2024-04-22T21:58:44.657532Z","shell.execute_reply":"2024-04-22T21:58:44.656214Z","shell.execute_reply.started":"2024-04-22T21:58:32.365155Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install rouge #Recall-Oriented Understudy for Gisting Evaluation, often referred as ROUGE score, is a metric used to evaluate text summarization and translation models\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:44.660994Z","iopub.status.busy":"2024-04-22T21:58:44.660378Z","iopub.status.idle":"2024-04-22T21:58:44.674706Z","shell.execute_reply":"2024-04-22T21:58:44.671222Z","shell.execute_reply.started":"2024-04-22T21:58:44.660948Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.notebook import tqdm\n","from transformers import Trainer, TrainingArguments\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling\n","from sklearn.model_selection import train_test_split\n","from rouge import Rouge"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:44.676595Z","iopub.status.busy":"2024-04-22T21:58:44.676157Z","iopub.status.idle":"2024-04-22T21:58:45.281250Z","shell.execute_reply":"2024-04-22T21:58:45.280223Z","shell.execute_reply.started":"2024-04-22T21:58:44.676560Z"},"trusted":true},"outputs":[],"source":["# Tokenize data using the gpt2 model \n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.add_special_tokens({'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'})\n","tokenizer.pad_token = '<PAD>'  # Set the padding token\n","\n","# Custom dataset\n","class ReviewDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len=512):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        review = self.data.loc[idx, 'Text']\n","        summary = f\"<BOS> {self.data.loc[idx, 'Summary']} <EOS>\"\n","\n","        review_encoding = self.tokenizer(review, truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n","        summary_encoding = self.tokenizer(summary, truncation=True, max_length=128, padding='max_length', return_tensors='pt')\n","\n","        return {\n","            'input_ids': review_encoding['input_ids'].squeeze(),\n","            'attention_mask': review_encoding['attention_mask'].squeeze(),\n","            'labels': summary_encoding['input_ids'].squeeze()\n","        }"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:45.283721Z","iopub.status.busy":"2024-04-22T21:58:45.283408Z","iopub.status.idle":"2024-04-22T21:58:45.296552Z","shell.execute_reply":"2024-04-22T21:58:45.295471Z","shell.execute_reply.started":"2024-04-22T21:58:45.283695Z"},"trusted":true},"outputs":[],"source":["# Split data\n","def split_data(data, test_size=0.25, random_state=42):\n","    train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n","    return train_data, test_data\n","\n","train_data, test_data = split_data(data)\n","train_data = train_data.reset_index(drop=True)\n","test_data = test_data.reset_index(drop=True)\n","\n","# Create datasets and dataloaders\n","train_dataset = ReviewDataset(train_data, tokenizer)\n","test_dataset = ReviewDataset(test_data, tokenizer)\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=data_collator, num_workers=2)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T21:58:45.298226Z","iopub.status.busy":"2024-04-22T21:58:45.297880Z","iopub.status.idle":"2024-04-22T22:04:11.020816Z","shell.execute_reply":"2024-04-22T22:04:11.019473Z","shell.execute_reply.started":"2024-04-22T21:58:45.298194Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [470/470 05:22, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>3.962100</td>\n","      <td>4.065368</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>3.722800</td>\n","      <td>4.016747</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=470, training_loss=4.686876613535779, metrics={'train_runtime': 322.8462, 'train_samples_per_second': 11.615, 'train_steps_per_second': 1.456, 'total_flos': 979845120000000.0, 'train_loss': 4.686876613535779, 'epoch': 5.0})"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)  # Resize the embedding layer\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=5,\n","    per_device_train_batch_size=8,\n","    evaluation_strategy='steps',\n","    eval_steps=200,\n","    logging_steps=10,\n","    save_strategy='steps',\n","    save_steps=200,\n","    learning_rate=5e-5,\n",")\n","\n","# Instantiate the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    data_collator=data_collator,\n",")\n","\n","# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:56:14.076677Z","iopub.status.idle":"2024-04-22T21:56:14.077183Z","shell.execute_reply":"2024-04-22T21:56:14.076949Z","shell.execute_reply.started":"2024-04-22T21:56:14.076927Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"kaggle/working/save_model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:56:14.078523Z","iopub.status.idle":"2024-04-22T21:56:14.078874Z","shell.execute_reply":"2024-04-22T21:56:14.078709Z","shell.execute_reply.started":"2024-04-22T21:56:14.078695Z"},"trusted":true},"outputs":[],"source":["test_data\n","test_data.to_csv(\"kaggle/working/test.csv\")"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T22:04:11.022912Z","iopub.status.busy":"2024-04-22T22:04:11.022169Z","iopub.status.idle":"2024-04-22T22:04:11.226323Z","shell.execute_reply":"2024-04-22T22:04:11.225042Z","shell.execute_reply.started":"2024-04-22T22:04:11.022875Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[   72,   717,  5071,  ..., 50259, 50259, 50259],\n","        [   72,  2904,  8155,  ..., 50259, 50259, 50259],\n","        [ 4053,  2861,   262,  ..., 50259, 50259, 50259],\n","        ...,\n","        [   72, 18548,  1975,  ..., 50259, 50259, 50259],\n","        [   69,   415,  3477,  ..., 50259, 50259, 50259],\n","        [ 2655,  6819,   783,  ..., 50259, 50259, 50259]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[   72,   717,  5071,  ...,  -100,  -100,  -100],\n","        [   72,  2904,  8155,  ...,  -100,  -100,  -100],\n","        [ 4053,  2861,   262,  ...,  -100,  -100,  -100],\n","        ...,\n","        [   72, 18548,  1975,  ...,  -100,  -100,  -100],\n","        [   69,   415,  3477,  ...,  -100,  -100,  -100],\n","        [ 2655,  6819,   783,  ...,  -100,  -100,  -100]])}\n"]}],"source":["for batch in test_loader:\n","    print(batch)\n","    break"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T22:53:50.378833Z","iopub.status.busy":"2024-04-22T22:53:50.378080Z","iopub.status.idle":"2024-04-22T23:16:31.088543Z","shell.execute_reply":"2024-04-22T23:16:31.087573Z","shell.execute_reply.started":"2024-04-22T22:53:50.378799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["processing data: 100%|██████████| 1000/1000 [22:40<00:00,  1.36s/it]\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge-1': {'r': 0.49044381915123364, 'p': 0.048237567641080295, 'f': 0.08426655343227403}, 'rouge-2': {'r': 0.1596052345757639, 'p': 0.011530906407555615, 'f': 0.019990795503886345}, 'rouge-l': {'r': 0.4445283729852865, 'p': 0.04315792205103801, 'f': 0.0754225513985582}}\n"]}],"source":["import torch\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.eval()\n","model.to(device)\n","generated_summaries = []\n","reference_summaries = []\n","for index, row in tqdm(data.iterrows(), total=len(data), desc='processing data'):\n","    if index == 538 :\n","        continue  # Skip processing this index\n","    if index== 859:\n","        continue\n","    review = row['Text']\n","    summary = row['Summary']\n","\n","    # Skip empty summaries\n","    if summary.strip() == '':\n","        continue\n","\n","    # Tokenize review and summary\n","    review_encoding = tokenizer(review, truncation=True, max_length=512, padding='max_length', return_tensors='pt')\n","    summary_encoding = tokenizer(summary, truncation=True, max_length=128, padding='max_length', return_tensors='pt')\n","\n","    input_ids = review_encoding['input_ids'].to(device)\n","    attention_mask = review_encoding['attention_mask'].to(device)\n","\n","    # Generate summary\n","    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=128, num_return_sequences=1, early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n","    \n","    if outputs is not None and len(outputs) > 0 and outputs[0] is not None:\n","        # Decode generated summary and reference summary\n","        tokens = []\n","        for token_id in outputs[0]:\n","            if token_id is not None:\n","                decoded_token = tokenizer.decode(token_id.item())\n","                if decoded_token == tokenizer.pad_token:\n","                    break\n","                tokens.append(decoded_token)\n","\n","        # Join tokens into a single string\n","        generated_summary = \"\".join(tokens) if tokens else ''\n","        reference_summary = summary\n","\n","        generated_summaries.append(generated_summary)\n","        reference_summaries.append(reference_summary)\n","    else:\n","        # Handle case where outputs is None or empty\n","        generated_summaries.append('')\n","        reference_summaries.append('')\n","\n","# Compute ROUGE scores\n","rouge = Rouge()\n","scores = rouge.get_scores(generated_summaries, reference_summaries, avg=True)\n","print(scores)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T23:16:43.792527Z","iopub.status.busy":"2024-04-22T23:16:43.792164Z","iopub.status.idle":"2024-04-22T23:16:43.799581Z","shell.execute_reply":"2024-04-22T23:16:43.798471Z","shell.execute_reply.started":"2024-04-22T23:16:43.792500Z"},"trusted":true},"outputs":[],"source":["# Accessing ROUGE-1 scores\n","rouge_1_f1 = scores['rouge-1']['f']\n","rouge_1_precision = scores['rouge-1']['p']\n","rouge_1_recall = scores['rouge-1']['r']"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T23:16:44.683788Z","iopub.status.busy":"2024-04-22T23:16:44.683420Z","iopub.status.idle":"2024-04-22T23:16:44.692001Z","shell.execute_reply":"2024-04-22T23:16:44.691040Z","shell.execute_reply.started":"2024-04-22T23:16:44.683762Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.08426655343227403"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["rouge_1_f1"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T23:24:20.835591Z","iopub.status.busy":"2024-04-22T23:24:20.834657Z","iopub.status.idle":"2024-04-22T23:24:22.184345Z","shell.execute_reply":"2024-04-22T23:24:22.183279Z","shell.execute_reply.started":"2024-04-22T23:24:20.835555Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ROUGE Scores: [{'rouge-1': {'r': 0.75, 'p': 0.18181818181818182, 'f': 0.29268292368828075}, 'rouge-2': {'r': 0.2857142857142857, 'p': 0.058823529411764705, 'f': 0.09756097277810835}, 'rouge-l': {'r': 0.625, 'p': 0.15151515151515152, 'f': 0.24390243588340277}}]\n"]}],"source":["# Input text and summary\n","input_text = \"The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound,and feels comfortable to play. However, some users have reported issues with the tuning stability.\"\n","input_summary = \"Good for beginners but has tuning stability issues.\"\n","\n","# Preprocess the input\n","input_encoding = tokenizer(input_text, truncation=True, max_length=512, padding='max_length', return_tensors='pt')\n","summary_encoding = tokenizer(input_summary, truncation=True, max_length=128, padding='max_length', return_tensors='pt')\n","\n","input_ids = input_encoding['input_ids'].to(device)\n","attention_mask = input_encoding['attention_mask'].to(device)\n","\n","# Generate summary\n","outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=128, num_return_sequences=1, early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n","\n","# Decode generated summary\n","if outputs[0] is not None:\n","    tokens = []\n","    for token_id in outputs[0]:\n","        if token_id is not None:\n","            decoded_token = tokenizer.decode(token_id.item())\n","            if decoded_token == tokenizer.pad_token:\n","                break\n","            tokens.append(decoded_token)\n","    generated_summary = \"\".join(tokens)\n","else:\n","    generated_summary = \"\"\n","\n","# Compute ROUGE scores\n","rouge_scores = rouge.get_scores(generated_summary, input_summary)\n","print(\"ROUGE Scores:\", rouge_scores)\n","# # Decode generated summary\n","# generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# # Compute ROUGE scores\n","# rouge_scores = rouge.get_scores(generated_summary, input_summary)\n","# print(\"ROUGE Scores:\", rouge_scores)\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T23:24:37.334248Z","iopub.status.busy":"2024-04-22T23:24:37.333566Z","iopub.status.idle":"2024-04-22T23:24:37.341530Z","shell.execute_reply":"2024-04-22T23:24:37.340612Z","shell.execute_reply.started":"2024-04-22T23:24:37.334217Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound,and feels comfortable to play. However, some users have reported issues with the tuning stability.'"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["generated_summary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":18,"sourceId":2157,"sourceType":"datasetVersion"},{"datasetId":4838594,"sourceId":8174586,"sourceType":"datasetVersion"},{"datasetId":4853774,"sourceId":8194820,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
